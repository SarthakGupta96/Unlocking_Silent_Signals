ğŸ¯ Unlocking Silent Signals
Unlocking Silent Signals is a realâ€‘time body language and emotion detection project built using MediaPipe Holistic and Machine Learning. It captures and analyzes key landmarks (face, hands, and body) from video frames, extracting meaningful data points to recognize and classify a personâ€™s emotions and gestures.

âš¡ï¸ Features
ğŸ” Realâ€‘Time Pose & Face Tracking: Leverages MediaPipe Holistic for highâ€‘precision landmark detection.

ğŸ–ï¸ Gesture & Emotion Recognition: Trained on custom datasets (Happy, Sad, Victorious, Fight) to classify body language and expressions.

ğŸ’» Live Demo: Displays prediction results overlayed on webcam feed.

ğŸ“ Custom Dataset Creation: Records MediaPipe landmark coordinates and labels (coords.csv) for easy training.

ğŸ¤– Machine Learning Model: Utilizes a trained scikitâ€‘learn model (model.pkl) for robust prediction.

ğŸ› ï¸ Easy Integration: Works with a laptop camera or any video stream.

ğŸ—„ï¸ Tech Stack
Python

MediaPipe Holistic (Face, Pose, Hands detection)

OpenCV (Video capture and display)

scikitâ€‘learn (Classification Model)

ğŸš€ Goal
To enable intelligent, privacyâ€‘aware applications by interpreting body language and expressions, making humanâ€‘computer interaction more seamless and contextâ€‘aware.
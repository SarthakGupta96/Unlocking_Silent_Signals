🎯 Unlocking Silent Signals
Unlocking Silent Signals is a real‑time body language and emotion detection project built using MediaPipe Holistic and Machine Learning. It captures and analyzes key landmarks (face, hands, and body) from video frames, extracting meaningful data points to recognize and classify a person’s emotions and gestures.

⚡️ Features
🔍 Real‑Time Pose & Face Tracking: Leverages MediaPipe Holistic for high‑precision landmark detection.

🖐️ Gesture & Emotion Recognition: Trained on custom datasets (Happy, Sad, Victorious, Fight) to classify body language and expressions.

💻 Live Demo: Displays prediction results overlayed on webcam feed.

📁 Custom Dataset Creation: Records MediaPipe landmark coordinates and labels (coords.csv) for easy training.

🤖 Machine Learning Model: Utilizes a trained scikit‑learn model (model.pkl) for robust prediction.

🛠️ Easy Integration: Works with a laptop camera or any video stream.

🗄️ Tech Stack
Python

MediaPipe Holistic (Face, Pose, Hands detection)

OpenCV (Video capture and display)

scikit‑learn (Classification Model)

🚀 Goal
To enable intelligent, privacy‑aware applications by interpreting body language and expressions, making human‑computer interaction more seamless and context‑aware.